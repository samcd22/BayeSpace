{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4f4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from inference_toolbox.parameter import Parameter\n",
    "from inference_toolbox.model import Model\n",
    "from inference_toolbox.likelihood import Likelihood\n",
    "from inference_toolbox.sampler import Sampler\n",
    "from inference_toolbox.visualiser import Visualiser\n",
    "from inference_toolbox.domain import Domain\n",
    "\n",
    "from data_processing.get_data import get_data\n",
    "# from gaussian_processor.gaussian_processor import GaussianProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1e21b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gp = GaussianProcessor(averaged_df, kernel = 'matern_white', data_norm='sqrt')\n",
    "# training_data, test_data = gp.train_test_split()\n",
    "# print(training_data)\n",
    "# gp.train_gp(training_data)\n",
    "# gp.test(test_data)\n",
    "# grid = box_gridder.get_grid([10,10,10])\n",
    "# gp.predict_from_gp(grid, threeD=True, save=True, log_results=True)\n",
    "# gp.animate() \n",
    "\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "if current_directory != '/project/':\n",
    "    os.chdir('/project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3038cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/data_processing/box_gridder.py:89: RuntimeWarning: invalid value encountered in divide\n",
      "  averages = sums/counts\n"
     ]
    }
   ],
   "source": [
    "# data_type = 'dummy'\n",
    "# data_params = {\n",
    "#     'data_type': 'dummy',\n",
    "#     'data_path': 'data',\n",
    "#     'sigma': 1,\n",
    "#     'model_select': 'log_gpm_alt_norm',\n",
    "#     'noise_dist': 'gaussian',\n",
    "#     'model': {\n",
    "#         'model_params':{\n",
    "#             'H': 10\n",
    "#         },\n",
    "#         'inference_params':{\n",
    "#             'I_y': 0.1,\n",
    "#             'I_z': 0.1,\n",
    "#             'Q': 3e13\n",
    "#         },\n",
    "#     },\n",
    "#     'domain': {\n",
    "#         'domain_select': 'cone_from_source_z_limited', \n",
    "#         'resolution': 20,\n",
    "#         'domain_params':{\n",
    "#             'r': 100,\n",
    "#             'theta': np.pi/8,\n",
    "#             'source': [0,0,10]}\n",
    "#     },\n",
    "#     'output_header': 'Concentration'\n",
    "# }\n",
    "\n",
    "data_type = 'real_gridded'\n",
    "data_params = {\n",
    "    'data_type': 'real_gridded',\n",
    "    'output_header': 'Concentration'\n",
    "}\n",
    "\n",
    "data = get_data(data_type, data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705fa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, testing_data = train_test_split(averaged_df, test_size=0.2)\n",
    "training_data, testing_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28eafd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameter series\n",
    "params = pd.Series({},dtype='float64')\n",
    "\n",
    "# Parameter Assignment\n",
    "I_y = Parameter(name = 'I_y', init_val=0.1, prior_select=\"gamma\")\n",
    "I_y.add_prior_param(\"mu\",0.1)\n",
    "I_y.add_prior_param(\"sigma\",0.1)\n",
    "params['I_y'] = I_y\n",
    "\n",
    "I_z = Parameter(name = 'I_z', init_val=0.1, prior_select=\"gamma\")\n",
    "I_z.add_prior_param(\"mu\",0.1)\n",
    "I_z.add_prior_param(\"sigma\",0.1)\n",
    "params['I_z'] = I_z\n",
    "\n",
    "Q = Parameter(name = 'Q', init_val=3e13, prior_select=\"gamma\")\n",
    "Q.add_prior_param(\"mu\",3e13)\n",
    "Q.add_prior_param(\"sigma\",1e13)\n",
    "params['Q'] = Q\n",
    "\n",
    "sigma = Parameter(name = 'sigma', init_val=1, prior_select=\"gamma\")\n",
    "sigma.add_prior_param(\"mu\",1)\n",
    "sigma.add_prior_param(\"sigma\",1)\n",
    "params['sigma'] = sigma\n",
    "\n",
    "# Model Assignment\n",
    "model = Model('log_gpm_alt_norm')\n",
    "model.add_model_param(\"H\",10)\n",
    "\n",
    "# Likelihood function assigmnent\n",
    "likelihood = Likelihood(\"gaussian\")\n",
    "# likelihood.add_likelihood_param(\"sigma\",0.5)\n",
    "# likelihood.add_likelihood_param(\"lambda_1\",1)\n",
    "# likelihood.add_likelihood_param(\"lambda_2\",0.05)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "data_path = 'results/gridded_drone_data_1/inference/general_instances'\n",
    "\n",
    "# Initialize the sampler\n",
    "# sampler = Sampler(params, model, likelihood, training_data, num_samples, show_sample_info = True, n_chains=4, thinning_rate=1,data_path = 'results/simulated_data_1/inference/general_instances')\n",
    "sampler = Sampler(params, \n",
    "                  model, \n",
    "                  likelihood, \n",
    "                  training_data, \n",
    "                  num_samples, \n",
    "                  show_sample_info = True, \n",
    "                  n_chains=4, \n",
    "                  thinning_rate=1,\n",
    "                  data_path = data_path)\n",
    "\n",
    "# Sample the parameters\n",
    "params_samples, chain_samples, fields = sampler.sample_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83666bb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Chain samples file does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# visualiser = Visualiser(testing_data, \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#                         params_samples, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#                         model, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m#                             data_params['model']['inference_params']['Q'],\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#                             data_params['sigma']])\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m visualiser \u001b[39m=\u001b[39m Visualiser(testing_data, \n\u001b[1;32m     16\u001b[0m                         params_samples, \n\u001b[1;32m     17\u001b[0m                         model, \n\u001b[1;32m     18\u001b[0m                         sampler\u001b[39m.\u001b[39;49mhyperparams, \n\u001b[1;32m     19\u001b[0m                         chain_samples\u001b[39m=\u001b[39;49mchain_samples,\n\u001b[1;32m     20\u001b[0m                         fields \u001b[39m=\u001b[39;49m fields, \n\u001b[1;32m     21\u001b[0m                         previous_instance \u001b[39m=\u001b[39;49m sampler\u001b[39m.\u001b[39;49minstance, \n\u001b[1;32m     22\u001b[0m                         data_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mresults/gridded_drone_data_1/inference/general_instances\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m visualiser\u001b[39m.\u001b[39mget_summary()\n\u001b[1;32m     25\u001b[0m visualiser\u001b[39m.\u001b[39mget_traceplot()\n",
      "File \u001b[0;32m/project/inference_toolbox/visualiser.py:56\u001b[0m, in \u001b[0;36mVisualiser.__init__\u001b[0;34m(self, test_data, samples, model, hyperparams, chain_samples, fields, previous_instance, data_path, include_test_points, suppress_prints, actual_values)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain_data_inputted:\n\u001b[1;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain_data_generated:\n\u001b[0;32m---> 56\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_samples(chain\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain_samples \u001b[39m=\u001b[39m chain_samples\n",
      "File \u001b[0;32m/project/inference_toolbox/visualiser.py:398\u001b[0m, in \u001b[0;36mVisualiser.load_samples\u001b[0;34m(self, chain)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(chain_full_path)\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mChain samples file does not exist!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    399\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     full_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/instance_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/samples.csv\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mException\u001b[0m: Chain samples file does not exist!"
     ]
    }
   ],
   "source": [
    "# visualiser = Visualiser(testing_data, \n",
    "#                         params_samples, \n",
    "#                         model, \n",
    "#                         sampler.hyperparams, \n",
    "#                         chain_samples=chain_samples,\n",
    "#                         fields = fields, \n",
    "#                         previous_instance = sampler.instance, \n",
    "#                         data_path = 'results/simulated_data_1/inference/general_instances', \n",
    "#                         actual_values=[\n",
    "#                             data_params['model']['inference_params']['I_y'], \n",
    "#                             data_params['model']['inference_params']['I_z'],\n",
    "#                             data_params['model']['inference_params']['Q'],\n",
    "#                             data_params['sigma']])\n",
    "\n",
    "visualiser = Visualiser(testing_data, \n",
    "                        params_samples, \n",
    "                        model, \n",
    "                        sampler.hyperparams, \n",
    "                        chain_samples=chain_samples,\n",
    "                        fields = fields, \n",
    "                        previous_instance = sampler.instance, \n",
    "                        data_path = data_path)\n",
    "\n",
    "visualiser.get_summary()\n",
    "visualiser.get_traceplot()\n",
    "visualiser.get_autocorrelations()\n",
    "\n",
    "domain = Domain('cone_from_source_z_limited', resolution=80)\n",
    "domain.add_domain_param('r', 100)\n",
    "domain.add_domain_param('theta', np.pi/8)\n",
    "domain.add_domain_param('source', [0,0,10])\n",
    "\n",
    "visualiser.visualise_results(domain = domain, name = 'small_scale_3D_plots', title='Log Concentration of Droplets', log_results=False)\n",
    "visualiser.animate(name = 'small_scale_3D_plots')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cab6123",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4836aab9230707cf36e93c729ff9a67bdbebd51947e18404ed5a25d63daeec60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
