{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4f4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from inference_toolbox.parameter import Parameter\n",
    "from inference_toolbox.model import Model\n",
    "from inference_toolbox.likelihood import Likelihood\n",
    "from inference_toolbox.sampler import Sampler\n",
    "from inference_toolbox.visualiser import Visualiser\n",
    "from inference_toolbox.domain import Domain\n",
    "\n",
    "from data_processing.normaliser import Normaliser\n",
    "from data_processing.box_gridder import BoxGridder\n",
    "# from gaussian_processor.gaussian_processor import GaussianProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657693e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import and select data.\n",
    "# all_data = pd.read_csv('data/total_data.csv')\n",
    "\n",
    "# # Import and select metadata.\n",
    "# metadata = pd.read_csv('data/data_summary.csv',\n",
    "#     usecols = ['Experiment', 'Wind_Dir', 'WindSpeed', 'boat.lat', 'boat.lon']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5874f43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# normaliser = Normaliser(all_data, metadata)\n",
    "\n",
    "# all_experiments = normaliser.get_experiments_list()\n",
    "\n",
    "# selected_experiments = np.delete(all_experiments, np.where(all_experiments == 'Control'))\n",
    "\n",
    "# normalised_data = normaliser.normalise_data(selected_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b91589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_gridder = BoxGridder(normalised_data)\n",
    "\n",
    "# averaged_df = box_gridder.get_averages([200,200,50],False)\n",
    "\n",
    "# # box_gridder.visualise_average_data(averaged_df)\n",
    "\n",
    "# # averaged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1e21b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gp = GaussianProcessor(averaged_df, kernel = 'matern_white', data_norm='sqrt')\n",
    "# training_data, test_data = gp.train_test_split()\n",
    "# print(training_data)\n",
    "# gp.train_gp(training_data)\n",
    "# gp.test(test_data)\n",
    "# grid = box_gridder.get_grid([10,10,10])\n",
    "# gp.predict_from_gp(grid, threeD=True, save=True, log_results=True)\n",
    "# gp.animate() \n",
    "\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "if current_directory != '/project/':\n",
    "    os.chdir('/project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3038cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy data\n",
    "log_dummy_data = pd.read_csv('data/log_dummy_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705fa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, testing_data = train_test_split(averaged_df, test_size=0.2)\n",
    "training_data, testing_data = train_test_split(log_dummy_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28eafd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/inference_toolbox/sampler.py:59: UserWarning: There are not enough devices to run parallel chains: expected 3 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(3)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc_obj = numpyro.infer.MCMC(kernel, num_warmup=self.n_warmup, num_samples=self.n_samples, num_chains=self.n_chains, thinning=self.thinning_rate)\n",
      "sample: 100%|██████████| 1250/1250 [00:04<00:00, 258.16it/s, 15 steps of size 1.66e-01. acc. prob=0.95]\n",
      "sample: 100%|██████████| 1250/1250 [00:00<00:00, 1700.09it/s, 15 steps of size 1.47e-01. acc. prob=0.93]\n",
      "sample: 100%|██████████| 1250/1250 [00:00<00:00, 1545.36it/s, 23 steps of size 2.07e-01. acc. prob=0.94]\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameter series\n",
    "params = pd.Series({},dtype='float64')\n",
    "\n",
    "# Parameter Assignment\n",
    "I_y = Parameter(name = 'I_y', init_val=0.1, prior_select=\"gamma\")\n",
    "I_y.add_prior_param(\"mu\",0.1)\n",
    "I_y.add_prior_param(\"sigma\",0.1)\n",
    "params['I_y'] = I_y\n",
    "\n",
    "I_z = Parameter(name = 'I_z', init_val=0.1, prior_select=\"gamma\")\n",
    "I_z.add_prior_param(\"mu\",0.1)\n",
    "I_z.add_prior_param(\"sigma\",0.1)\n",
    "params['I_z'] = I_z\n",
    "\n",
    "Q = Parameter(name = 'Q', init_val=3e13, prior_select=\"gamma\")\n",
    "Q.add_prior_param(\"mu\",3e13)\n",
    "Q.add_prior_param(\"sigma\",1e13)\n",
    "params['Q'] = Q\n",
    "\n",
    "# Model Assignment\n",
    "model = Model('log_GPM_alt_norm')\n",
    "model.add_model_param(\"H\",10)\n",
    "\n",
    "# Likelihood function assigmnent\n",
    "likelihood = Likelihood(\"gaussian_fixed_sigma\")\n",
    "likelihood.add_likelihood_param(\"sigma\",0.5)\n",
    "# likelihood.add_likelihood_param(\"lambda_1\",1)\n",
    "# likelihood.add_likelihood_param(\"lambda_2\",0.05)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# Initialize the sampler\n",
    "sampler = Sampler(params, model, likelihood, training_data, num_samples, show_sample_info = True, n_chains=3, thinning_rate=1)\n",
    "\n",
    "# Sample the parameters\n",
    "params_samples, chain_samples, fields = sampler.sample_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83666bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance\n",
      "{'RMSE': 0.012597064, 'chain_1': {'fields': {'diverging': 0}, 'I_y': {'lower': 0.09810175225138665, 'mean': 0.10008548200130463, 'upper': 0.10218458957970142, 'tau': 1}, 'I_z': {'lower': 0.051608691550791265, 'mean': 0.09767859801650047, 'upper': 0.16298888921737664, 'tau': 6}, 'Q': {'lower': 16218791870464.0, 'mean': 28728634638336.0, 'upper': 41211384561664.0, 'tau': 4}}, 'chain_2': {'fields': {'diverging': 0}, 'I_y': {'lower': 0.09808762073516845, 'mean': 0.0999995544552803, 'upper': 0.10210934914648533, 'tau': 3}, 'I_z': {'lower': 0.05157414339482784, 'mean': 0.0933670848608017, 'upper': 0.15837226808071136, 'tau': 5}, 'Q': {'lower': 16269286152601.6, 'mean': 28342667444224.0, 'upper': 40842110068326.4, 'tau': 5}}, 'chain_3': {'fields': {'diverging': 0}, 'I_y': {'lower': 0.09809441864490509, 'mean': 0.09999395161867142, 'upper': 0.10204036198556424, 'tau': 1}, 'I_z': {'lower': 0.0535097474232316, 'mean': 0.10161711648106575, 'upper': 0.16398955881595612, 'tau': 3}, 'Q': {'lower': 17286637971046.4, 'mean': 30221124239360.0, 'upper': 42103325956505.58, 'tau': 4}}, 'overall': {'I_y': {'lower': 0.09888665502270062, 'mean': 0.10003657142321268, 'upper': 0.10117947086691856, 'tau': 1.6666666666666667}, 'I_z': {'lower': 0.06955667448540528, 'mean': 0.10043575242161751, 'upper': 0.13551833070814606, 'tau': 4.666666666666667}, 'Q': {'lower': 21423518052078.934, 'mean': 29173717751125.336, 'upper': 36159066437495.46, 'tau': 4.333333333333333}}}\n"
     ]
    }
   ],
   "source": [
    "visualiser = Visualiser(testing_data, params_samples, model, sampler.hyperparams, chain_samples=chain_samples,fields = fields, previous_instance = sampler.instance, data_path = 'results/inference')\n",
    "visualiser.get_summary()\n",
    "# visualiser.get_traceplot()\n",
    "# visualiser.get_autocorrelations()\n",
    "\n",
    "# domain = Domain('cone_from_source_z_limited', resolution=80)\n",
    "# domain.add_domain_param('r', 100)\n",
    "# domain.add_domain_param('theta', np.pi/8)\n",
    "# domain.add_domain_param('source', [0,0,10])\n",
    "\n",
    "# visualiser.visualise_results(domain = domain, name = 'small_scale_3D_plots', title='Log Concentration of Droplets', log_results=False)\n",
    "# visualiser.animate(name = 'small_scale_3D_plots')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cab6123",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4836aab9230707cf36e93c729ff9a67bdbebd51947e18404ed5a25d63daeec60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
