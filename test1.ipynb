{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from controllers.inference_controllers.sandbox import Sandbox\n",
    "from controllers.inference_controllers.generator import Generator\n",
    "from controllers.inference_controllers.optimiser import Optimiser\n",
    "\n",
    "from toolboxes.plotting_toolbox.domain import Domain\n",
    "from toolboxes.inference_toolbox.parameter import Parameter\n",
    "from toolboxes.inference_toolbox.model import Model\n",
    "from toolboxes.inference_toolbox.likelihood import Likelihood\n",
    "\n",
    "#current_directory = os.getcwd()\n",
    "#if current_directory != '/project/':\n",
    "    #os.chdir('/project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'data_type': 'simulated_data',\n",
    "    'model': {\n",
    "        'model_select': 'sarah_model',\n",
    "        'model_params':{\n",
    "            'u': 7.5\n",
    "        },\n",
    "        'inference_params':{\n",
    "            'I_y': 0.1,\n",
    "            'I_z': 0.1,\n",
    "            'Q': 3e13,\n",
    "            'sigma': 1,\n",
    "            'x_0': 0,\n",
    "            'y_0': 0,\n",
    "            'z_0':0\n",
    "        }\n",
    "    },\n",
    "    'domain':{\n",
    "        'domain_select': 'cone_from_source_z_limited',\n",
    "        'domain_params': {\n",
    "            'r': 100,\n",
    "            'theta': np.pi/8,\n",
    "            'source': [0,0,0]\n",
    "        },\n",
    "        'resolution': 20\n",
    "    },\n",
    "    'noise_dist': 'gaussian',\n",
    "    'noise_level': 1,\n",
    "    'output_header': 'Concentration',\n",
    "}\n",
    "\n",
    "# data_params = {\n",
    "#     'data_type': 'normalised_data',\n",
    "#     'data_select': 'GBR_data',\n",
    "#     'normaliser_select': 'GBR_normaliser',\n",
    "#     'normaliser_params':{\n",
    "#         'experiments_list': [\n",
    "#             'Exp1',\n",
    "#             'Exp2',\n",
    "#             'Exp3',\n",
    "#             'Exp4',\n",
    "#             'Exp5',\n",
    "#             'Exp6',\n",
    "#             'Exp7',\n",
    "#             'Exp8',\n",
    "#             'Exp9',\n",
    "#             'Exp10',\n",
    "#             'Exp11',\n",
    "#             'Exp12',\n",
    "#         ],\n",
    "#         'meta_data_select': 'GBR_data_summary',\n",
    "#         'input_header': 'Concentration'\n",
    "#     },\n",
    "#     'log':True,\n",
    "#     'output_header': 'Concentration',\n",
    "#     'gridding': [100,100,25]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "default_params = {\n",
    "    'infered_params':pd.Series({\n",
    "        'model_params':pd.Series({\n",
    "            'I_y': Parameter('I_y', prior_select = 'gamma', default_value=0.1).add_prior_param('mu', 0.1).add_prior_param('sigma',0.1),\n",
    "            'I_z': Parameter('I_z', prior_select = 'gamma', default_value=0.1).add_prior_param('mu', 0.1).add_prior_param('sigma',0.1),\n",
    "            'Q': Parameter('Q', prior_select = 'gamma', default_value=3e13).add_prior_param('mu', 3e13).add_prior_param('sigma',1e13),\n",
    "            'x_0': Parameter('x_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "            'y_0': Parameter('y_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "            'z_0': Parameter('z_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "        }),\n",
    "        'likelihood_params':pd.Series({\n",
    "            'sigma': Parameter('sigma', prior_select = 'gamma', default_value=1).add_prior_param('mu', 1).add_prior_param('sigma',1)\n",
    "        })\n",
    "    }),\n",
    "    'model':Model('sarah_model').add_model_param('u',7.5),\n",
    "    'likelihood': Likelihood('gaussian'),\n",
    "    'sampler': {\n",
    "        'n_samples': 1000,\n",
    "        'n_chains': 3,\n",
    "        'thinning_rate': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "results_name = 'diffusioncoeff_sensitivityanalysis_inferred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1250/1250 [00:09<00:00, 131.17it/s, 7 steps of size 3.03e-01. acc. prob=0.94] \n",
      "sample: 100%|██████████| 1250/1250 [00:01<00:00, 1054.92it/s, 15 steps of size 3.68e-01. acc. prob=0.94]\n",
      "sample: 100%|██████████| 1250/1250 [00:01<00:00, 728.45it/s, 15 steps of size 3.93e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance\n"
     ]
    }
   ],
   "source": [
    "sandbox = Sandbox(results_name=results_name, \n",
    "                  data_params=data_params,\n",
    "                  default_params=default_params)\n",
    "\n",
    "visualiser = sandbox.run()\n",
    "visualiser.get_summary()\n",
    "visualiser.get_traceplot()\n",
    "visualiser.get_autocorrelations()\n",
    "\n",
    "domain = Domain('cone_from_source_z_limited', resolution=50)\n",
    "domain.add_domain_param('r', 1000)\n",
    "domain.add_domain_param('theta', np.pi/8)\n",
    "domain.add_domain_param('source', [0,0,0])\n",
    "\n",
    "visualiser.visualise_results(domain = domain, name = 'small_scale_3D_plots', title='Log Concentration of Droplets', log_results=False)\n",
    "visualiser.animate(name = 'small_scale_3D_plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(results_name=results_name, \n",
    "                  data_params=data_params,\n",
    "                  default_params=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on varying sigma_mu...\n",
      "Generating instance 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1250/1250 [00:19<00:00, 64.95it/s, 1 steps of size 5.93e-02. acc. prob=0.74]  \n",
      "sample: 100%|██████████| 1250/1250 [00:02<00:00, 480.46it/s, 31 steps of size 6.76e-02. acc. prob=0.76]\n",
      "sample: 100%|██████████| 1250/1250 [00:01<00:00, 761.60it/s, 31 steps of size 1.79e-01. acc. prob=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating instance 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1250/1250 [00:12<00:00, 102.46it/s, 15 steps of size 1.40e-01. acc. prob=0.49]\n",
      "sample: 100%|██████████| 1250/1250 [00:03<00:00, 316.87it/s, 63 steps of size 7.31e-02. acc. prob=0.80] \n",
      "sample: 100%|██████████| 1250/1250 [00:02<00:00, 450.95it/s, 11 steps of size 1.87e-01. acc. prob=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating instance 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1250/1250 [00:42<00:00, 29.27it/s, 63 steps of size 3.86e-02. acc. prob=0.91] \n",
      "sample: 100%|██████████| 1250/1250 [00:08<00:00, 150.50it/s, 63 steps of size 7.42e-02. acc. prob=0.80] \n",
      "sample: 100%|██████████| 1250/1250 [00:03<00:00, 331.93it/s, 23 steps of size 2.30e-01. acc. prob=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating instance 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1250/1250 [00:12<00:00, 96.62it/s, 31 steps of size 1.20e-01. acc. prob=0.64] \n",
      "sample: 100%|██████████| 1250/1250 [00:02<00:00, 431.08it/s, 63 steps of size 7.18e-02. acc. prob=0.83]\n",
      "sample: 100%|██████████| 1250/1250 [00:04<00:00, 309.83it/s, 15 steps of size 1.87e-01. acc. prob=0.82]\n"
     ]
    }
   ],
   "source": [
    "analysis_iterations = {\n",
    "    'parameters_1':\n",
    "    [\n",
    "        'sigma_mu'\n",
    "    ],\n",
    "    'parameters_2':\n",
    "    [\n",
    "        'sigma_sigma'\n",
    "\n",
    "    ],\n",
    "    'values_1':\n",
    "    [\n",
    "        np.array([0.5, 1])     \n",
    "    ],\n",
    "\n",
    "    'values_2':\n",
    "    [\n",
    "        np.array([0.5, 1]) \n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in range(len(analysis_iterations['parameters_1'])):\n",
    "    parameter_1 = analysis_iterations['parameters_1'][i]\n",
    "    parameter_2 = analysis_iterations['parameters_2'][i]\n",
    "\n",
    "    print('Working on varying ' + parameter_1 + '...')\n",
    "    values_1 = analysis_iterations['values_1'][i]\n",
    "    values_2 = analysis_iterations['values_2'][i]\n",
    "    inputs = generator.vary_two_parameters(parameter_1, parameter_2, values_1, values_2, scale_1='linear', scale_2='linear', plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
