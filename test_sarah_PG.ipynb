{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all neccessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from controllers.inference_controllers.sandbox import Sandbox\n",
    "from controllers.inference_controllers.generator import Generator\n",
    "from controllers.inference_controllers.optimiser import Optimiser\n",
    "\n",
    "from toolboxes.plotting_toolbox.domain import Domain\n",
    "from toolboxes.inference_toolbox.parameter import Parameter\n",
    "from toolboxes.inference_toolbox.model import Model\n",
    "from toolboxes.inference_toolbox.likelihood import Likelihood\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# if current_directory != '/project/':\n",
    "#     os.chdir('/project/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define how the data is to be generated and what default inputs should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'data_type': 'simulated_data',\n",
    "    'model': {\n",
    "        'model_select': 'sarah_model_PG',\n",
    "        'model_params':{\n",
    "            'u': 7.5\n",
    "        },\n",
    "        'inference_params':{\n",
    "            #'I_y': 0.1,\n",
    "            #'I_z': 0.1,\n",
    "            'Q': 3e13,\n",
    "            'sigma': 1,\n",
    "            'x_0': 0,\n",
    "            'y_0': 0,\n",
    "            'z_0':0\n",
    "        }\n",
    "    },\n",
    "    'domain':{\n",
    "        'domain_select': 'cone_from_source_z_limited',\n",
    "        'domain_params': {\n",
    "            'r': 100,\n",
    "            'theta': np.pi/8,\n",
    "            'source': [0,0,0]\n",
    "        },\n",
    "        'resolution': 20\n",
    "    },\n",
    "    'noise_dist': 'gaussian',\n",
    "    'noise_level': 1,\n",
    "    'output_header': 'Concentration',\n",
    "}\n",
    "\n",
    "# data_params = {\n",
    "#     'data_type': 'normalised_data',\n",
    "#     'data_select': 'GBR_data',\n",
    "#     'normaliser_select': 'GBR_normaliser',\n",
    "#     'normaliser_params':{\n",
    "#         'experiments_list': [\n",
    "#             'Exp1',\n",
    "#             'Exp2',\n",
    "#             'Exp3',\n",
    "#             'Exp4',\n",
    "#             'Exp5',\n",
    "#             'Exp6',\n",
    "#             'Exp7',\n",
    "#             'Exp8',\n",
    "#             'Exp9',\n",
    "#             'Exp10',\n",
    "#             'Exp11',\n",
    "#             'Exp12',\n",
    "#         ],\n",
    "#         'meta_data_select': 'GBR_data_summary',\n",
    "#         'input_header': 'Concentration'\n",
    "#     },\n",
    "#     'log':True,\n",
    "#     'output_header': 'Concentration',\n",
    "#     'gridding': [100,100,25]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "default_params = {\n",
    "    'infered_params':pd.Series({\n",
    "        'model_params':pd.Series({\n",
    "            #'I_y': Parameter('I_y', prior_select = 'gamma', default_value=0.1).add_prior_param('mu', 0.1).add_prior_param('sigma',0.1),\n",
    "            #'I_z': Parameter('I_z', prior_select = 'gamma', default_value=0.1).add_prior_param('mu', 0.1).add_prior_param('sigma',0.1),\n",
    "            'Q': Parameter('Q', prior_select = 'gamma', default_value=3e13).add_prior_param('mu', 3e13).add_prior_param('sigma',1e13),\n",
    "            'x_0': Parameter('x_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "            'y_0': Parameter('y_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "            'z_0': Parameter('z_0', prior_select = 'uniform', default_value=0).add_prior_param('low', -3).add_prior_param('high',3),\n",
    "        }),\n",
    "        'likelihood_params':pd.Series({\n",
    "            'sigma': Parameter('sigma', prior_select = 'gamma', default_value=1).add_prior_param('mu', 1).add_prior_param('sigma',1)\n",
    "        })\n",
    "    }),\n",
    "    'model':Model('sarah_model_PG').add_model_param('u',10),\n",
    "    'likelihood': Likelihood('gaussian'),\n",
    "    'sampler': {\n",
    "        'n_samples': 10000,\n",
    "        'n_chains': 3,\n",
    "        'thinning_rate': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "results_name = 'sarah_results_simulated_PG'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox ##\n",
    "\n",
    "Create an instance with the inputted default parameters and visualise it in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'results/inference_results/sarah_results_simulated_PG/general_instances/.DS_Store/hyperparams.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vm/9g52bp016dlcdtfbhhkwm1_80000gn/T/ipykernel_53852/1806310287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   default_params=default_params)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvisualiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvisualiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvisualiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_traceplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/USYD/Thesis/PhD_project/controllers/inference_controllers/sandbox.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Runs the sampler for the allotted number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Initialises the sampler object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/USYD/Thesis/PhD_project/toolboxes/inference_toolbox/sampler.py\u001b[0m in \u001b[0;36msample_all\u001b[0;34m(self, rng_key)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Generates the allotted number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdata_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_data_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# If data does not already exist, then generate samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/USYD/Thesis/PhD_project/toolboxes/inference_toolbox/sampler.py\u001b[0m in \u001b[0;36mcheck_data_exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minstance_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/hyperparams.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0minstance_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'results/inference_results/sarah_results_simulated_PG/general_instances/.DS_Store/hyperparams.json'"
     ]
    }
   ],
   "source": [
    "sandbox = Sandbox(results_name=results_name, \n",
    "                  data_params=data_params,\n",
    "                  default_params=default_params)\n",
    "\n",
    "visualiser = sandbox.run()\n",
    "visualiser.get_summary()\n",
    "visualiser.get_traceplot()\n",
    "visualiser.get_autocorrelations()\n",
    "\n",
    "domain = Domain('cone_from_source_z_limited', resolution=80)\n",
    "domain.add_domain_param('r', 1000)\n",
    "domain.add_domain_param('theta', np.pi/8)\n",
    "domain.add_domain_param('source', [0,0,0])\n",
    "\n",
    "visualiser.visualise_results(domain = domain, name = 'small_scale_3D_plots', title='Log Concentration of Droplets', log_results=False)\n",
    "visualiser.animate(name = 'small_scale_3D_plots')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
