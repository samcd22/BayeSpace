{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584f66e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc   # For manual garbage collection.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import njit\n",
    "import math\n",
    "\n",
    "experiment = 'Exp1'\n",
    "\n",
    "# Import and select data.\n",
    "all_data = pd.read_csv('total_data.csv',\n",
    "    usecols = ['gps.lat', 'gps.lon', 'altitudeRelative', 'Concentration', 'Experiment','Transect','Peak_Dist'],\n",
    ")\n",
    "all_data = all_data[all_data['Experiment'] == experiment]\n",
    "all_data = all_data.drop(columns = ['Experiment'])\n",
    "\n",
    "# Import and select metadata.\n",
    "experiment_metadata = pd.read_csv('data_summary.csv',\n",
    "    usecols = ['Experiment', 'Wind_Dir', 'WindSpeed', 'boat.lat', 'boat.lon']\n",
    ")\n",
    "experiment_metadata = experiment_metadata[experiment_metadata['Experiment'] == experiment]\n",
    "wind_dir = experiment_metadata['Wind_Dir'].values[0]\n",
    "wind_speed = experiment_metadata['WindSpeed'].values[0]\n",
    "\n",
    "# Converting lat and lon to distances from boat in downwind and crosswind directions.\n",
    "all_data['dist_lat'] = (all_data['gps.lat'] - experiment_metadata['boat.lat'].values[0]) * 111000\n",
    "all_data['dist_lon'] = (all_data['gps.lon'] - experiment_metadata['boat.lon'].values[0]) * 111000\n",
    "all_data['x'] = all_data['dist_lon'] * np.cos(270 - wind_dir) + all_data['dist_lat'] * np.sin(270 - wind_dir)\n",
    "all_data['y'] = all_data['dist_lon'] * np.cos(360 - wind_dir) + all_data['dist_lat'] * np.sin(360 - wind_dir)\n",
    "all_data['z'] = all_data['altitudeRelative']\n",
    "all_data['T'] = all_data['Transect']\n",
    "all_data['PD'] = all_data['Peak_Dist']\n",
    "\n",
    "# Modify concentrations.\n",
    "all_data['Concentration'] = all_data['Concentration']\n",
    "\n",
    "# Split data, 80% for training and 20% for testing, shuffling rows first.\n",
    "all_data = all_data.drop(columns = ['altitudeRelative', 'dist_lat', 'dist_lon', 'gps.lat', 'gps.lon','Transect','Peak_Dist'])\n",
    "all_data = np.asarray(all_data)   # Prepare for Numba.\n",
    "np.random.seed(1)                 # Ensure the same split each time.\n",
    "np.random.shuffle(all_data)\n",
    "training_data, testing_data = np.split(all_data, [int(0.8 * len(all_data))])\n",
    "\n",
    "# Release unused memory.\n",
    "del(all_data)\n",
    "del(experiment)\n",
    "del(experiment_metadata)\n",
    "del(wind_dir)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94605400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 1000...\n",
      "Running sample 1000...\n",
      "Running sample 2000...\n",
      "Running sample 2000...\n",
      "Running sample 3000...\n",
      "Running sample 3000...\n",
      "Running sample 4000...\n",
      "Running sample 4000...\n"
     ]
    }
   ],
   "source": [
    "# Inference and model parameters.\n",
    "H = 0\n",
    "\n",
    "ss =np.array([0.2, 0.2, 10])\n",
    "\n",
    "prior_param_1 = np.array([0.33, 0.86, 1000])\n",
    "prior_param_2 = np.array([1, 1, 1000])\n",
    "dists = ['gaussian','gaussian','gaussian']\n",
    "\n",
    "sigma = 1\n",
    "\n",
    "params_init = prior_param_1.copy()\n",
    "\n",
    "\n",
    "class Sampler:\n",
    "    def __init__(self,H, wind_speed, ss, data, dist, prior_param_1, prior_param_2, sigma):\n",
    "        self.H = H\n",
    "        self.u = wind_speed \n",
    "        self.ss = ss\n",
    "        self.data = data\n",
    "        self.dist = dist\n",
    "        self.prior_param_1 = prior_param_1\n",
    "        self.prior_param_2 = prior_param_2\n",
    "        self.sigma = sigma\n",
    "        self.N_data = data[:,1].size\n",
    "        \n",
    "    # Function for calculating the conditional probability for parameters a, b or Q.\n",
    "    def log_prob_params(self,params, log_lhood, param_select):\n",
    "        if self.dist[param_select] == 'gamma':\n",
    "            prob = (self.prior_param_1[param_select] - 1)*np.log(params[param_select])-params[param_select]/self.prior_param_2[param_select]+log_lhood\n",
    "        elif self.dist[param_select] == 'gaussian':\n",
    "            prob =  -(params[param_select]-self.prior_param_1[param_select])**2/(2*self.prior_param_2[param_select]**2)+log_lhood        \n",
    "        elif self.dist[param_select] == 'uniform':\n",
    "            prob = log_lhood\n",
    "        return  prob\n",
    "\n",
    "    def step(self,param_select, current_params):\n",
    "        if self.dist[param_select] == \"gamma\":\n",
    "            return np.random.gamma(current_params[param_select],self.ss[param_select])\n",
    "        if self.dist[param_select] == \"gaussian\":\n",
    "            proposed = -1\n",
    "            while proposed <= 0:\n",
    "                proposed = np.random.normal(current_params[param_select],self.ss[param_select])\n",
    "            return proposed\n",
    "        if self.dist[param_select] == \"uniform\":\n",
    "            return np.random.normal(current_params[param_select],self.ss[param_select])\n",
    "    \n",
    "    # MCMC Sampler for a, b or Q.\n",
    "    def sample_params(self,params, precalc2, param_select):\n",
    "\n",
    "        # Set current and proposed values for a, b, Q and sigma.\n",
    "        current_params = params\n",
    "        proposed_params = current_params.copy()\n",
    "        proposed_params[param_select] =  self.step(param_select,current_params)\n",
    "\n",
    "        condition = [0,0,0,1]\n",
    "\n",
    "        # Calculating the conditional probability of current and proposed a,b,Q and sigma.\n",
    "        log_l_curr_params = -sum(precalc2)/(2*self.sigma**2)\n",
    "        log_l_prop_params = -sum(precalc2)/(2*self.sigma**2)\n",
    "\n",
    "        log_p_prop_params = self.log_prob_params(proposed_params, log_l_prop_params, param_select)\n",
    "        log_p_curr_params = self.log_prob_params(current_params, log_l_curr_params, param_select)\n",
    "        \n",
    "        # Calculating the probability of stepping (for the Metropolis Hastings Acceptance Criteria)\n",
    "        log_p_step_back, log_p_step_forward = self.get_p_step_back_forward(param_select, current_params, proposed_params)       \n",
    "        \n",
    "        # Acceptance criteria\n",
    "        alpha = np.exp(log_p_prop_params - log_p_curr_params + log_p_step_back - log_p_step_forward)\n",
    "    \n",
    "        # Acceptance criteria.\n",
    "        if np.random.uniform(low = 0, high = 1) < np.min([1,alpha]):\n",
    "            return proposed_params, 1\n",
    "        else:\n",
    "            return current_params, 0\n",
    "\n",
    "    def get_p_step_back_forward(self, param_select, current_params, proposed_params):\n",
    "        if self.dist[param_select] == 'gaussian':\n",
    "            return 1, 1\n",
    "\n",
    "        elif self.dist[param_select] == 'uniform':\n",
    "            return 1, 1\n",
    "        \n",
    "        elif self.dist[param_select] == 'gamma':\n",
    "            back = stats.gamma.logpdf(current_params[param_select], proposed_params[param_select], scale=1/self.ss[param_select])\n",
    "            forward = stats.gamma.logpdf(proposed_params[param_select], current_params[param_select], scale=1/self.ss[param_select])\n",
    "            return back, forward\n",
    "            \n",
    "    # Full MCMC sampler.\n",
    "    def sample_process(self,N_samples):\n",
    "        # Intialisation. Pre-allocate memory space for the data where relevant.\n",
    "        params_means = np.empty((N_samples, len(params_init)))    # rows = N_samples, cols = len(params_init).\n",
    "        params_means[:] = np.NaN\n",
    "        params_samples = params_means.copy()\n",
    "        params = params_init\n",
    "        count = 0\n",
    "        negysqr = -self.data[:,2]**2\n",
    "        piu = np.pi * self.u\n",
    "        zdownsqr = -(self.data[:,3] - H)**2\n",
    "        zupsqr = -(self.data[:,3] + H)**2\n",
    "\n",
    "        accept_tot_0, accept_tot_1, accept_tot_2, accept_tot_3 = 0, 0, 0, 0\n",
    "\n",
    "        tot_accepted = 0\n",
    "        for j in range(N_samples):\n",
    "            count += 1\n",
    "            if (count % 1000 == 0):\n",
    "                print('Running sample ' + str(count) + '...')    # Print progress every 1000th sample.\n",
    "\n",
    "            precalc1 = 2 * params[0] * self.data[:,1]**params[1]\n",
    "            precalc2 = (params[2] / precalc1 * piu * np.exp(negysqr / precalc1) * (np.exp(zdownsqr / precalc1) + np.exp(zupsqr / precalc1)) - self.data[:,0])**2\n",
    "\n",
    "            params, accept_0 = self.sample_params(params,precalc2,0) # a\n",
    "            params, accept_1 = self.sample_params(params,precalc2,1) # b\n",
    "            params, accept_2 = self.sample_params(params,precalc2,2) # Q \n",
    "\n",
    "            accept_tot_0 += accept_0\n",
    "            accept_tot_1 += accept_1\n",
    "            accept_tot_2 += accept_2\n",
    "\n",
    "            params_samples[j] = params.T\n",
    "            params_means[j] = np.mean(params_samples[:count][:], axis = 0)\n",
    "\n",
    "        print('Sampling complete.')\n",
    "        print('a Acceptance Rate: ', accept_tot_0/N_samples)\n",
    "        print('b Acceptance Rate: ', accept_tot_1/N_samples)\n",
    "        print('Q Acceptance Rate: ', accept_tot_2/N_samples)\n",
    "\n",
    "        return params_samples, params_means\n",
    "\n",
    "\n",
    "# Run sampling.\n",
    "np.random.seed(117)\n",
    "sampler = Sampler(H, wind_speed, ss, training_data, dists, prior_param_1, prior_param_2, sigma)\n",
    "params_samples, params_means = sampler.sample_process(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for traceplots.\n",
    "def traceplots(x, xnames = None, title = None):\n",
    "\n",
    "    N, d = x.shape\n",
    "    fig = plt.figure()\n",
    "    left, tracewidth, histwidth = 0.1, 0.65, 0.15\n",
    "    bottom, rowheight = 0.1, 0.8/d\n",
    "    spacing = 0.05\n",
    "\n",
    "    for i in range(d):\n",
    "        # Set the location of the trace and histogram viewports,\n",
    "        # starting with the first dimension from the bottom of the canvas.\n",
    "        rowbottom = bottom + i * rowheight\n",
    "        rect_trace = (left, rowbottom, tracewidth, rowheight)\n",
    "        rect_hist = (left + tracewidth, rowbottom, histwidth, rowheight)\n",
    "\n",
    "        # First set of trace plot axes.\n",
    "        if i == 0:\n",
    "            ax_trace = fig.add_axes(rect_trace)\n",
    "            ax_trace.plot(x[:,i])\n",
    "            ax_trace.set_xlabel(\"Sample Count\")\n",
    "            ax_tr0 = ax_trace\n",
    "\n",
    "        # Other sets of trace plot axes that share the first trace's x-axis.\n",
    "        # Make tick labels invisible so they don't clutter up the plot.\n",
    "        elif i > 0:\n",
    "            ax_trace = fig.add_axes(rect_trace, sharex=ax_tr0)\n",
    "            ax_trace.plot(x[:,i])\n",
    "            plt.setp(ax_trace.get_xticklabels(), visible=False)\n",
    "\n",
    "        # Title at the top.\n",
    "        if i == d-1 and title is not None:\n",
    "            plt.title(title)\n",
    "\n",
    "        # Trace y-axis labels.\n",
    "        if xnames is not None:\n",
    "            ax_trace.set_ylabel(xnames[i])\n",
    "\n",
    "        # Trace histograms at the right.\n",
    "        ax_hist = fig.add_axes(rect_hist, sharey=ax_trace)\n",
    "        ax_hist.hist(x[:,i], orientation='horizontal', bins=50)\n",
    "        plt.setp(ax_hist.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax_hist.get_yticklabels(), visible=False)\n",
    "        xlim = ax_hist.get_xlim()\n",
    "        ax_hist.set_xlim([xlim[0], 1.1*xlim[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "traceplots(params_samples, xnames = ['a', 'b', 'Q','sigma'], title = 'MCMC samples')\n",
    "traceplots(params_means, xnames = ['a', 'b', 'Q','sigma'], title = 'MCMC means')\n",
    "\n",
    "print(params_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b247fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Plume Model for concentration.\n",
    "def C_func(x,y,z,u,a,b,Q,H):\n",
    "    C = Q / (2*a*x**b*np.pi*u)*(np.exp(-(y**2)/(2*a*x**b)))*(np.exp(-(z-H)**2/(2*a*x**b))+np.exp(-(z+H)**2/(2*a*x**b)))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b381ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting slices of the plume at set Z values using the mean values of the parameters.\n",
    "\n",
    "params_mean = params_means[-1]\n",
    "x = np.linspace(0.1, 200, 201)\n",
    "y = np.linspace(-20, 20, 201)\n",
    "#z = np.linspace(0, 400, 201)\n",
    "X,Y = np.meshgrid(x, y)\n",
    "Z = 5\n",
    "C = C_func(X, Y, Z, wind_speed, params_mean[0], params_mean[1], params_mean[2], H)\n",
    "plt.pcolor(X, Y, C, shading = 'auto')\n",
    "plt.colorbar()\n",
    "plt.title('Plume concentration at z = ' + str(Z))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "print('Inferred means: a = ', round(params_mean[0], 2), ', b = ', round(params_mean[1], 2), ', Q = ', params_mean[2],'.', sep = '')\n",
    "\n",
    "del(x)\n",
    "del(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045dc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the RMSE of this new model based on the data\n",
    "def predict(params, u, H, data):\n",
    "    negysqr = -data[:,2]**2\n",
    "    piu = np.pi * u\n",
    "    zdownsqr = -(data[:,3] - H)**2\n",
    "    zupsqr = -(data[:,3] + H)**2\n",
    "    precalc1 = np.array(2 * params[0] * data[:,1]**params[1])\n",
    "    predictions = params[2] / precalc1 * piu * np.exp(negysqr / precalc1) * (np.exp(zdownsqr / precalc1) + np.exp(zupsqr / precalc1))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def RMSE_func(predictions, data):    \n",
    "    precalc2 = (predictions - data[:,0])**2\n",
    "\n",
    "    RMSE = np.sqrt(sum(precalc2)/data.shape[0])\n",
    "    print('RMSE = ' + str(RMSE))\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "predictions = predict(params_mean,wind_speed,H,testing_data)\n",
    "RMSE = RMSE_func(predictions,testing_data)\n",
    "\n",
    "data_range = np.max(testing_data[:,0]) - np.min(testing_data[:,0])\n",
    "\n",
    "print('Range = ' + str(data_range))\n",
    "\n",
    "# # saving_samples = pd.DataFrame({'a':abQ_samples[:,0],'b':abQ_samples[:,1],'Q':abQ_samples[:,2]})\n",
    "# saving_samples = pd.DataFrame(abQ_samples,columns=['a','b','Q'])\n",
    "# saving_samples.to_csv('samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values of a, b and Q\n",
    "def print_vals(params_samples):\n",
    "\n",
    "    params_samples = np.array(params_samples)\n",
    "    vals = ['a','b','Q','sigma']\n",
    "    for i in range(params_samples.shape[1]):\n",
    "        param_samples = params_samples[:,i]\n",
    "        param_90 = np.sort(param_samples)[int(np.floor(param_samples.size*0.9))]\n",
    "        param_50 = np.sort(param_samples)[int(np.floor(param_samples.size*0.5))]\n",
    "        param_10 = np.sort(param_samples)[int(np.floor(param_samples.size*0.1))]\n",
    "\n",
    "        print(vals[i] + ' Mean = ' + str(np.mean(params_samples[:,i])) + ', Confidence ' + str([param_10,param_90]))\n",
    "        \n",
    "print_vals(params_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2907d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_transects(testing_data, predicted_data):\n",
    "    unique_transects = np.unique(testing_data[:,4])\n",
    "    for transect in unique_transects:\n",
    "        peak_dist = []\n",
    "        test_transect_data = []\n",
    "        predict_transect_data = []\n",
    "        for i in range(testing_data.shape[0]):\n",
    "            if testing_data[i,4] == transect:\n",
    "                peak_dist.append(testing_data[i,5])\n",
    "                test_transect_data.append(testing_data[i,0])\n",
    "                predict_transect_data.append(predicted_data[i])\n",
    "        \n",
    "        indices = np.argsort(peak_dist)\n",
    "        peak_dist = np.array(peak_dist)[indices]\n",
    "        test_transect_data = np.array(test_transect_data)[indices]\n",
    "        predict_transect_data = np.array(predict_transect_data)[indices]\n",
    "        \n",
    "        plt.plot(peak_dist,test_transect_data)\n",
    "        plt.show()\n",
    "        plt.plot(peak_dist,predict_transect_data)\n",
    "        plt.show()\n",
    "    \n",
    "compare_transects(testing_data,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69388fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f132f6c4237cba2d865fbf0594f77c169f5660f7b7d39a372371b1e40073e867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
