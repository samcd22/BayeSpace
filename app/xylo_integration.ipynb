{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/build/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from inference_toolbox.model import Model, add_model, delete_model\n",
    "from inference_toolbox.likelihood import Likelihood\n",
    "from inference_toolbox.parameter import Parameter\n",
    "from visualisation_toolbox.domain import Domain\n",
    "from controllers.sampler import Sampler\n",
    "from visualisation_toolbox.visualiser import Visualiser\n",
    "from data_processing.sim_data_processor import SimDataProcessor\n",
    "from data_processing.raw_data_processor import RawDataProcessor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import jax\n",
    "\n",
    "os.chdir('/PhD_project/')\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "RawDataProcessor - construction.json file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/PhD_project/app/data_processing/raw_data_processor.py:204\u001b[0m, in \u001b[0;36mRawDataProcessor._load_data\u001b[0;34m(self, data_filepath)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_filepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/construction.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    205\u001b[0m         construction_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed_raw_data/xylo_test_aves/construction.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m      8\u001b[0m processor_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_header\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounts\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maves\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestep\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     17\u001b[0m raw_data_processor \u001b[38;5;241m=\u001b[39m RawDataProcessor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxylo_test_project\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     18\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxylo_test_aves\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     19\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXYLO_processor\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     20\u001b[0m                                       processor_params\u001b[38;5;241m=\u001b[39mprocessor_params)\n\u001b[0;32m---> 22\u001b[0m gridded_data \u001b[38;5;241m=\u001b[39m \u001b[43mraw_data_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# model = Model('log_gpm_norm').add_fixed_model_param('H', 5).add_fixed_model_param('Q',3.41e13)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# # likelihood = Likelihood('gaussian_percentage_error')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# likelihood = Likelihood('gaussian')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# visualiser.generate_report(report_title)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# visualiser.embed_report()\u001b[39;00m\n",
      "File \u001b[0;32m/PhD_project/app/data_processing/raw_data_processor.py:139\u001b[0m, in \u001b[0;36mRawDataProcessor.process_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    This is the main function of the RawDataProcessor class that processes the raw data using the specified data processor and parameters.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    If data has already been processed, this function loads the data.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        - tuple: A tuple containing two DataFrames, training data and test data.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_data_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor_func()\n",
      "File \u001b[0;32m/PhD_project/app/data_processing/raw_data_processor.py:196\u001b[0m, in \u001b[0;36mRawDataProcessor._check_data_exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/PhD_project/app/data_processing/raw_data_processor.py:213\u001b[0m, in \u001b[0;36mRawDataProcessor._load_data\u001b[0;34m(self, data_filepath)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    211\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRawDataProcessor - construction.json file under the data_name \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_data_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoes not match processor parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRawDataProcessor - construction.json file not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: RawDataProcessor - construction.json file not found"
     ]
    }
   ],
   "source": [
    "report_title = ''\n",
    "\n",
    "# sim_model = Model('log_gpm_norm').add_fixed_model_param('H', 5).add_fixed_model_param('I_y',0.04).add_fixed_model_param('I_z',0.0016).add_fixed_model_param('Q',3.41e13)\n",
    "# sim_domain = Domain('cone_from_source_z_limited').add_domain_param('r',1000).add_domain_param('theta',np.pi/8).add_domain_param('source', [0,0,5]).add_domain_param('resolution',20)\n",
    "\n",
    "# sim_data_processor = SimDataProcessor('F_log_gaus_noise_pn_10', sim_model, sim_domain,noise_dist='gaussian' ,noise_percentage=0.1)\n",
    "\n",
    "processor_params = {\n",
    "    'output_header': 'Counts',\n",
    "    'identifier':'aves',\n",
    "    'tax_group': 'class',\n",
    "    'num_x_cells': 10,\n",
    "    'num_y_cells': 10,\n",
    "    'timestep': 'year'\n",
    "}\n",
    "\n",
    "raw_data_processor = RawDataProcessor('xylo_test_project', \n",
    "                                      'xylo_test_aves', \n",
    "                                      'XYLO_processor', \n",
    "                                      processor_params=processor_params)\n",
    "\n",
    "gridded_data = raw_data_processor.process_data()\n",
    "\n",
    "\n",
    "# model = Model('log_gpm_norm').add_fixed_model_param('H', 5).add_fixed_model_param('Q',3.41e13)\n",
    "# # likelihood = Likelihood('gaussian_percentage_error')\n",
    "# likelihood = Likelihood('gaussian')\n",
    "# # I_y_and_I_z = Parameter(name=['I_y','I_z'],prior_select='log_norm', multi_mode=True).add_prior_param('peak',  [[0.22,0.2],[0.16,0.12],[0.11,0.08],[0.08,0.06], [0.06,0.03], [0.04,0.016]] ).add_prior_param('overall_scale', 1)\n",
    "# # I_y = Parameter(name='I_y',prior_select='log_norm', multi_mode=True).add_prior_param('peak',  [0.22,0.16,0.11,0.08,0.06,0.04] ).add_prior_param('overall_scale', 5)\n",
    "# # I_z = Parameter(name='I_z',prior_select='log_norm', multi_mode=True).add_prior_param('peak',  [0.2,0.12,0.08,0.06,0.03,0.016] ).add_prior_param('overall_scale', 5)\n",
    "\n",
    "# I_y = Parameter(name='I_y',prior_select='uniform').add_prior_param('low',  0.0001).add_prior_param('high', 1)\n",
    "# I_z = Parameter(name='I_z',prior_select='uniform').add_prior_param('low',  0.0001).add_prior_param('high', 1)\n",
    "\n",
    "# # I_y_and_I_z = Parameter(name=['I_y','I_z'],prior_select='log_norm').add_prior_param('peak', [0.11,0.11] ).add_prior_param('scale',[[1,0],[0,1]])\n",
    "# # Q = Parameter(name='Q',prior_select='log_norm', order = 13).add_prior_param('peak',  1).add_prior_param('scale', 0.001)\n",
    "# # sigma = Parameter(name='sigma',prior_select='log_norm').add_prior_param('peak',  1).add_prior_param('scale', 1)\n",
    "# # sigma = Parameter(name='sigma',prior_select='uniform').add_prior_param('low',  0.0001).add_prior_param('high', 5)\n",
    "# sigma = Parameter(name='sigma',prior_select='uniform').add_prior_param('low',  0.0001).add_prior_param('high', 5)\n",
    "# error = Parameter(name='error',prior_select='uniform').add_prior_param('low',  0.0001).add_prior_param('high', 1)\n",
    "# # error = Parameter(name='error',prior_select='log_norm').add_prior_param('peak',  0.8).add_prior_param('scale', 0.00001)\n",
    "# # inference_params = pd.Series({'I_y_and_I_z': I_y_and_I_z, 'sigma':sigma})\n",
    "# # inference_params = pd.Series({'I_y_and_I_z': I_y_and_I_z, 'error':error})\n",
    "# # inference_params = pd.Series({'I_y_and_I_z': I_y_and_I_z})\n",
    "# # inference_params = pd.Series({'I_y': I_y, 'I_z': I_z, 'error':error})\n",
    "# inference_params = pd.Series({'I_y': I_y, 'I_z': I_z, 'sigma':sigma})\n",
    "\n",
    "\n",
    "# # sampler = Sampler(inference_params, model, likelihood, sim_data_processor, n_samples = 10000, n_chains=3)\n",
    "# sampler = Sampler(inference_params, model, likelihood, raw_data_processor, n_samples = 10000, n_chains=3)\n",
    "# sampler.sample_all()\n",
    "\n",
    "# visualiser = Visualiser(sampler)\n",
    "# visualiser.get_traceplots()\n",
    "\n",
    "# domain = Domain('cone_from_source_z_limited').add_domain_param('r',1000).add_domain_param('theta',np.pi/8).add_domain_param('source', [0,0,1]).add_domain_param('resolution',40)\n",
    "# domain.add_domain_param('z_slice', 0)\n",
    "# domain.add_domain_param('y_slice', 0)\n",
    "# domain.add_domain_param('x_slice', 100)\n",
    "\n",
    "# # visualiser.show_predictions(domain, 'test', title = 'Concentration of Droplets', plot_type='3D')\n",
    "# # visualiser.show_predictions(domain, 'test', title = 'Concentration of Droplets', plot_type='2D_slice')\n",
    "# visualiser.get_autocorrelations()\n",
    "# visualiser.get_summary()\n",
    "\n",
    "# Q_ref = {\n",
    "#             'vals' : [2.82e13, 3.11e13, 2.89e13, 4.83e13],\n",
    "#             'labels': ['250m','200m','750m','1000m'] \n",
    "#         }\n",
    "\n",
    "# I_y_and_I_z_ref = {\n",
    "#             'vals' : [[0.22,0.2],[0.16,0.12],[0.11,0.08],[0.08,0.06], [0.06,0.03], [0.04,0.016]],\n",
    "#             'labels': ['A','B','C','D','E','F'] \n",
    "#         }\n",
    "\n",
    "# I_y_ref = {\n",
    "#             'vals' : [0.22,0.16,0.11,0.08,0.06,0.04],\n",
    "#             'labels': ['A','B','C','D','E','F'] \n",
    "#         }\n",
    "\n",
    "# I_z_ref = {'vals' : [0.2,0.12,0.08,0.06,0.03,0.016],\n",
    "#             'labels': ['A','B','C','D','E','F'] \n",
    "#         }\n",
    "\n",
    "# visualiser.plot_prior('sigma', [0.0001,5])\n",
    "# # visualiser.plot_prior('error', [0,1])\n",
    "# # visualiser.plot_prior('I_y_and_I_z', [[0.0001,0.3],[0.0001,0.3]], I_y_and_I_z_ref)\n",
    "\n",
    "# visualiser.plot_prior('I_y', [0.0001,0.5], I_y_ref)\n",
    "# visualiser.plot_prior('I_z', [0.0001,0.5], I_z_ref)\n",
    "\n",
    "# visualiser.plot_posterior('sigma', [0.0001,5])\n",
    "# # visualiser.plot_posterior('error', [0,1])\n",
    "# # visualiser.plot_posterior('I_y_and_I_z', [[0.0001,0.3],[0.0001,0.3]], I_y_and_I_z_ref)\n",
    "\n",
    "# visualiser.plot_posterior('I_y', [0.0001,0.5], I_y_ref)\n",
    "# visualiser.plot_posterior('I_z', [0.0001,0.5], I_z_ref)\n",
    "\n",
    "# visualiser.generate_report(report_title)\n",
    "# visualiser.embed_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
